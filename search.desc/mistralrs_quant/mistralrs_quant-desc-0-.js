searchState.loadedDescShard("mistralrs_quant", 0, "The Client holds its persistent connection inside a Mutex …\nThis layer has a weight that is parallelized along the …\nDevice/configurable intelligent matrix multiplication\nQuantized method for a quantized matmul.\nThis layer has no parallelization\nThis layer has a weight that is parallelized along the …\nThe Server maintains persistent connections.\nOffset for the quant type. UQFF always serializes the …\nAdd a delta weight from LoRA to the weights. This should …\nIf the quant is backed by a qmatmul.\nBegin tracking stats into an ImatrixLayerStats\nBroadcasts the given ID over all persistent connections.\nCompute the appropriate KV shard. This handles KV head …\nCompute the number of KV groups, taking into account KV …\nWeight dtype and device\nEnd tracking stats into an ImatrixLayerStats. Returns the …\nCompute matmul of <code>self</code> and <code>a</code>. <code>self</code> should contain the …\nCompute matmul of <code>self</code> and <code>a</code>. <code>self</code> should contain the …\nCompute matmul of <code>self</code> and <code>a</code>. <code>self</code> should contain the …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCompute matrix-matrix product, optionally casting to f16 …\nCompute matrix-matrix product, optionally casting to f16 …\nCompute matrix-matrix product, optionally casting to f16 …\nBinds the listener and then accepts exactly <code>n_nodes</code> …\nFactor by which the weight size is reduced over the given …\nCompute quantized matrix-matrix product, optionally …\nCompute quantized matrix-matrix product, optionally …\nQuantize the model into HQQ\nIf a quantized method, return the activation dtype.\nReceives the broadcasted ID from the persistent stream.\nNOT meant for external calling\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreates a wrapper around multiple memory mapped file and …\nCreates a wrapper around a memory mapped file and …\nInitializes a <code>VarBuilder</code> that retrieves tensors stored in …")