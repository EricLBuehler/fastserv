[mistralrs-core/src/models/deepseek2.rs:201:9] &xs.to_dtype(DType::F32)?.mean_all()? = Tensor[0.0031020532; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:263:9] &q.to_dtype(DType::F32)?.mean_all()? = Tensor[-0.011941212; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:264:9] &k.to_dtype(DType::F32)?.mean_all()? = Tensor[-0.07878022; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:266:9] &self.softmax_scale = 0.114721395

hidden_states tensor(0.0031, device='mps:0')
query_states tensor(-0.0139, device='mps:0')
key_states tensor(0.0747, device='mps:0')
softmax_scale 0.1147213867929261




[mistralrs-core/src/models/deepseek2.rs:201:9] &xs.to_dtype(DType::F32)?.mean_all()? = Tensor[0.0031020532; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:205:9] &q.to_dtype(DType::F32)?.mean_all()? = Tensor[-0.011752563; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:217:9] &compressed_kv.to_dtype(DType::F32)?.mean_all()? = Tensor[0.045891125; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:265:9] &self.softmax_scale = 0.114721395

hidden_states tensor(0.0031, device='mps:0')
q tensor(-0.0118, device='mps:0')
compressed_kv tensor(0.0458, device='mps:0')
softmax_scale 0.1147213867929261





[mistralrs-core/src/models/deepseek2.rs:201:9] &xs.to_dtype(DType::F32)?.mean_all()? = Tensor[0.0031020532; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:205:9] &q.to_dtype(DType::F32)?.mean_all()? = Tensor[-0.011752563; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:217:9] &compressed_kv.to_dtype(DType::F32)?.mean_all()? = Tensor[0.045891125; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:238:9] &kv.to_dtype(DType::F32)?.mean_all()? = Tensor[-0.0021880628; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:244:9] &q_pe.to_dtype(DType::F32)?.mean_all()? = Tensor[0.032593843; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:245:9] &k_pe.to_dtype(DType::F32)?.mean_all()? = Tensor[0.19234705; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:249:9] &q_pe.to_dtype(DType::F32)?.mean_all()? = Tensor[0.032027893; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:250:9] &k_pe.to_dtype(DType::F32)?.mean_all()? = Tensor[-0.22937846; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:272:9] &self.softmax_scale = 0.114721395
[mistralrs-core/src/models/deepseek2.rs:289:9] &attn_out.to_dtype(DType::F32)?.mean_all()? = Tensor[-0.0005417123; f32, metal:4294968635]

hidden_states tensor(0.0031, device='mps:0')
q tensor(-0.0118, device='mps:0')
compressed_kv tensor(0.0458, device='mps:0')
kv tensor(-0.0022, device='mps:0')
q_pe tensor(0.0325, device='mps:0')
k_pe tensor(0.1925, device='mps:0')
q_pe tensor(0.0261, device='mps:0')
k_pe tensor(0.2310, device='mps:0')
softmax_scale 0.1147213867929261
attn_output tensor(-0.0002, device='mps:0')


# Copied from transformers.models.llama.modeling_llama.rotate_half
def rotate_half(x):
    """Rotates half the hidden dims of the input."""
    x1 = x[..., : x.shape[-1] // 2]
    x2 = x[..., x.shape[-1] // 2 :]
    return torch.cat((-x2, x1), dim=-1)


# Copied from transformers.models.llama.modeling_llama.apply_rotary_pos_emb
def apply_rotary_pos_emb(q, k, cos, sin, position_ids, unsqueeze_dim=1):
    """Applies Rotary Position Embedding to the query and key tensors.

    Args:
        q (`torch.Tensor`): The query tensor.
        k (`torch.Tensor`): The key tensor.
        cos (`torch.Tensor`): The cosine part of the rotary embedding.
        sin (`torch.Tensor`): The sine part of the rotary embedding.
        position_ids (`torch.Tensor`):
            The position indices of the tokens corresponding to the query and key tensors. For example, this can be
            used to pass offsetted position ids when working with a KV-cache.
        unsqueeze_dim (`int`, *optional*, defaults to 1):
            The 'unsqueeze_dim' argument specifies the dimension along which to unsqueeze cos[position_ids] and
            sin[position_ids] so that they can be properly broadcasted to the dimensions of q and k. For example, note
            that cos[position_ids] and sin[position_ids] have the shape [batch_size, seq_len, head_dim]. Then, if q and
            k have the shape [batch_size, heads, seq_len, head_dim], then setting unsqueeze_dim=1 makes
            cos[position_ids] and sin[position_ids] broadcastable to the shapes of q and k. Similarly, if q and k have
            the shape [batch_size, seq_len, heads, head_dim], then set unsqueeze_dim=2.
    Returns:
        `tuple(torch.Tensor)` comprising of the query and key tensors rotated using the Rotary Position Embedding.
    """
    cos = cos[position_ids].unsqueeze(unsqueeze_dim)
    sin = sin[position_ids].unsqueeze(unsqueeze_dim)

    b, h, s, d = q.shape
    q = q.view(b, h, s, d // 2, 2).transpose(4, 3).reshape(b, h, s, d)

    b, h, s, d = k.shape
    k = k.view(b, h, s, d // 2, 2).transpose(4, 3).reshape(b, h, s, d)

    q_embed = (q * cos) + (rotate_half(q) * sin)
    k_embed = (k * cos) + (rotate_half(k) * sin)
    return q_embed, k_embed


[mistralrs-core/src/models/deepseek2.rs:201:9] &xs.to_dtype(DType::F32)?.mean_all()? = Tensor[0.0031020532; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:205:9] &q.to_dtype(DType::F32)?.mean_all()? = Tensor[-0.011752563; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:217:9] &compressed_kv.to_dtype(DType::F32)?.mean_all()? = Tensor[0.045891125; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:238:9] &kv.to_dtype(DType::F32)?.mean_all()? = Tensor[-0.0021880628; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:244:9] &q_pe.to_dtype(DType::F32)?.mean_all()? = Tensor[0.032593843; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:245:9] &k_pe.to_dtype(DType::F32)?.mean_all()? = Tensor[0.19234705; f32, metal:4294968635]
[mistralrs-core/src/layers.rs:922:9] &self.cos.to_dtype(DType::F32)?.mean_all()? = Tensor[0.12473239; f32, metal:4294968635]
[mistralrs-core/src/layers.rs:923:9] &self.sin.to_dtype(DType::F32)?.mean_all()? = Tensor[0.1314414; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:249:9] &q_pe.to_dtype(DType::F32)?.mean_all()? = Tensor[-0.1362028; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:250:9] &k_pe.to_dtype(DType::F32)?.mean_all()? = Tensor[0.57974386; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:272:9] &self.softmax_scale = 0.114721395
[mistralrs-core/src/models/deepseek2.rs:289:9] &attn_out.to_dtype(DType::F32)?.mean_all()? = Tensor[-0.00028744567; f32, metal:4294968635]

hidden_states tensor(0.0031, device='mps:0')
q tensor(-0.0118, device='mps:0')
compressed_kv tensor(0.0458, device='mps:0')
kv tensor(-0.0022, device='mps:0')
q_pe tensor(0.0325, device='mps:0')
k_pe tensor(0.1925, device='mps:0')
cos tensor(0.8249, device='mps:0')
sin tensor(0.1400, device='mps:0')
q_pe tensor(0.0261, device='mps:0')
k_pe tensor(0.2310, device='mps:0')
softmax_scale 0.1147213867929261
attn_output tensor(-0.0002, device='mps:0')










self.base=10000 self.scaling_factor=40 dim=64
low=10 high=23
inv_freq=tensor([1.0000e+00, 7.4989e-01, 5.6234e-01, 4.2170e-01, 3.1623e-01, 2.3714e-01,
        1.7783e-01, 1.3335e-01, 1.0000e-01, 7.4989e-02, 5.6234e-02, 3.9007e-02,
        2.6879e-02, 1.8378e-02, 1.2448e-02, 8.3345e-03, 5.5000e-03, 3.5620e-03,
        2.2494e-03, 1.3705e-03, 7.9057e-04, 4.1499e-04, 1.7783e-04, 3.3338e-05,
        2.5000e-05, 1.8747e-05, 1.4059e-05, 1.0542e-05, 7.9057e-06, 5.9284e-06,
        4.4457e-06, 3.3338e-06], dtype=torch.float32)
_mscale=1.0

hidden_states tensor(0.0031, device='mps:0')
q tensor(-0.0118, device='mps:0')
compressed_kv tensor(0.0458, device='mps:0')
kv tensor(-0.0022, device='mps:0')
cos tensor(0.8249, device='mps:0')
sin tensor(0.1400, device='mps:0')
q_pe tensor(0.0325, device='mps:0')
k_pe tensor(0.1925, device='mps:0')
cos tensor(0.8249, device='mps:0')
sin tensor(0.1400, device='mps:0')
q_pe tensor(0.0261, device='mps:0')
k_pe tensor(0.2310, device='mps:0')
softmax_scale 0.1147213867929261
attn_output tensor(-0.0002, device='mps:0')

[mistralrs-core/src/layers.rs:845:9] &cfg.rope_theta = 10000.0
[mistralrs-core/src/layers.rs:845:9] factor = 40.0
[mistralrs-core/src/layers.rs:845:9] cfg.qk_rope_head_dim = 64
[mistralrs-core/src/layers.rs:866:9] low = 10.0
[mistralrs-core/src/layers.rs:866:9] high = 23.0
inv_freq=[[ 1.0000e0, 7.4989e-1, 5.6234e-1, 4.2170e-1, 3.1623e-1, 2.3714e-1, 1.7783e-1,
  1.3335e-1, 1.0000e-1, 7.4989e-2, 5.6234e-2, 3.9007e-2, 2.6879e-2, 1.8378e-2,
  1.2448e-2, 8.3345e-3, 5.5000e-3, 3.5620e-3, 2.2494e-3, 1.3705e-3, 7.9057e-4,
  4.1499e-4, 1.7783e-4, 3.3338e-5, 2.5000e-5, 1.8747e-5, 1.4059e-5, 1.0542e-5,
  7.9057e-6, 5.9284e-6, 4.4457e-6, 3.3338e-6]]
Tensor[[1, 32], f32, metal:4294968635]
[mistralrs-core/src/layers.rs:881:9] &mscale = 1.0
[mistralrs-core/src/layers.rs:884:9] &cos.to_dtype(DType::F32)?.mean_all()? = Tensor[0.12473239; f32, metal:4294968635]
[mistralrs-core/src/layers.rs:885:9] &sin.to_dtype(DType::F32)?.mean_all()? = Tensor[0.1314414; f32, metal:4294968635]

[mistralrs-core/src/models/deepseek2.rs:201:9] &xs.to_dtype(DType::F32)?.mean_all()? = Tensor[0.0031020532; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:205:9] &q.to_dtype(DType::F32)?.mean_all()? = Tensor[-0.011752563; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:217:9] &compressed_kv.to_dtype(DType::F32)?.mean_all()? = Tensor[0.045891125; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:238:9] &kv.to_dtype(DType::F32)?.mean_all()? = Tensor[-0.0021880628; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:244:9] &q_pe.to_dtype(DType::F32)?.mean_all()? = Tensor[0.032593843; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:245:9] &k_pe.to_dtype(DType::F32)?.mean_all()? = Tensor[0.19234705; f32, metal:4294968635]
[mistralrs-core/src/layers.rs:928:9] &self.cos.to_dtype(DType::F32)?.mean_all()? = Tensor[0.12473239; f32, metal:4294968635]
[mistralrs-core/src/layers.rs:929:9] &self.sin.to_dtype(DType::F32)?.mean_all()? = Tensor[0.1314414; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:249:9] &q_pe.to_dtype(DType::F32)?.mean_all()? = Tensor[-0.1362028; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:250:9] &k_pe.to_dtype(DType::F32)?.mean_all()? = Tensor[0.57974386; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:272:9] &self.softmax_scale = 0.114721395
[mistralrs-core/src/models/deepseek2.rs:289:9] &attn_out.to_dtype(DType::F32)?.mean_all()? = Tensor[-0.00028744567; f32, metal:4294968635]














hidden_states tensor(0.0031, device='mps:0')
q tensor(-0.0118, device='mps:0')
compressed_kv tensor(0.0458, device='mps:0')
kv tensor(-0.0022, device='mps:0')
q_pe tensor(0.0325, device='mps:0')
k_pe tensor(0.1925, device='mps:0')
q_pe tensor(0.0261, device='mps:0')
k_pe tensor(0.2310, device='mps:0')
softmax_scale 0.1147213867929261
attn_output tensor(-0.0002, device='mps:0')

[mistralrs-core/src/models/deepseek2.rs:201:9] &xs.to_dtype(DType::F32)?.mean_all()? = Tensor[0.0031020532; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:205:9] &q.to_dtype(DType::F32)?.mean_all()? = Tensor[-0.011752563; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:217:9] &compressed_kv.to_dtype(DType::F32)?.mean_all()? = Tensor[0.045891125; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:238:9] &kv.to_dtype(DType::F32)?.mean_all()? = Tensor[-0.0021880628; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:244:9] &q_pe.to_dtype(DType::F32)?.mean_all()? = Tensor[0.032593843; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:245:9] &k_pe.to_dtype(DType::F32)?.mean_all()? = Tensor[0.19234705; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:249:9] &q_pe.to_dtype(DType::F32)?.mean_all()? = Tensor[0.07006398; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:250:9] &k_pe.to_dtype(DType::F32)?.mean_all()? = Tensor[0.19443369; f32, metal:4294968635]
[mistralrs-core/src/models/deepseek2.rs:272:9] &self.softmax_scale = 0.114721395
[mistralrs-core/src/models/deepseek2.rs:289:9] &attn_out.to_dtype(DType::F32)?.mean_all()? = Tensor[0.00016288075; f32, metal:4294968635]